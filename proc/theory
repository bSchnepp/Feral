Totally overhaul the scheduler

Each socket is represented with a tree. The first level of the tree is always how many SMT threads are available (we consider CMT as totally separate cores. Bulldozer is weird, so ignore it.)
Each branch then has the number of actual cores on the socket. Thus, it is *always* 3 traversals to get to a given core. Each branch stores it's children, and a given score for availability on
the set of units (try to keep this O(1), O(logN) is bad here because we're gonna eventually have these huge gigantic datacenters for cloud gaming and anything beyond "basically instant" is unacceptable.)

We should, in order to avoid rescheduling cores (VERY EXPENSIVE BAD BAD BAD), try to keep utilization of a given core under 70%. When we *absolutely must* go over that, we prioritize the fastest cores first,
and keep this going to avoid stressing the system too hard.

We now need to figure out how to actually schedule them: a queue would guarantee O(1) performance, but then we need kmalloc() and it's not cache-friendly.
We could use a priority queue, but then we'll be O(logN), and this is going to be horrible for big massive gaming clusters like some sort of cloud gaming solution, since it's
not "basically instant always" (say, we have 2^16 nodes, and we go full on with being distributed, then we'll take *forever* to actually add a task or not. This is BAD).

We assume there is around 1024 tasks per core (to avoid growing the priority queue). We increase it's size by 1.5x when it overflows, and try
to reschedule the processes to run on other cores when this happens, so this one core can resize the priority queue, then possibly
bring in tasks back in?

Or, we could just use a queue and then enqueue and dequeue as needed...?

As always, since this is a core part of the kernel, anything less than perfect is totally unacceptable.
